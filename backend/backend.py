import asyncio
import json
import os
import base64
import datetime
from typing import Optional, Dict, Any

from fastapi import FastAPI, WebSocket, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from google import genai
from google.genai import types
from openai import AsyncOpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv(override=True)

# Initialize FastAPI app
app = FastAPI(
    title="AI Healthcare Assistant API",
    description="Backend API for AI Healthcare Assistant with Gemini Live and Medicine Scanner",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize clients
gemini_api_key = os.getenv('GOOGLE_API_KEY')
openai_api_key = os.getenv('OPENAI_API_KEY')
MODEL = "gemini-live-2.5-flash-preview"

if not gemini_api_key:
    raise ValueError("GOOGLE_API_KEY environment variable is required")
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY environment variable is required")

gemini_client = genai.Client(api_key=gemini_api_key)
openai_client = AsyncOpenAI(api_key=openai_api_key)

# Pydantic models
class MedicineScanRequest(BaseModel):
    input: str  # Base64 string or URL

class TextExtractRequest(BaseModel):
    text: str

class HealthResponse(BaseModel):
    success: bool
    result: str
    error: Optional[str] = None

# Session management functions
def load_previous_session_handle():
    try:
        with open('session_handle.json', 'r') as f:
            data = json.load(f)
            handle = data.get('previous_session_handle', None)
            session_time = data.get('session_time', None)
            
            if handle and session_time:
                session_datetime = datetime.datetime.fromisoformat(session_time)
                current_time = datetime.datetime.now()
                time_diff = current_time - session_datetime
                
                if time_diff.total_seconds() < 60:
                    print(f"Loaded previous session handle: {handle} (created {time_diff.total_seconds():.1f}s ago)")
                    return handle
                else:
                    print(f"Previous session handle expired ({time_diff.total_seconds():.1f}s ago, > 60s)")
                    return None
            else:
                print("No valid session handle or time found")
                return None
    except FileNotFoundError:
        print("No previous session file found")
        return None
    except Exception as e:
        print(f"Error loading session handle: {e}")
        return None

def save_previous_session_handle(handle):
    current_time = datetime.datetime.now().isoformat()
    with open('session_handle.json', 'w') as f:
        json.dump({
            'previous_session_handle': handle,
            'session_time': current_time
        }, f)
    print(f"Saved session handle with timestamp: {current_time}")

# Medicine Scanner Class
class MedicineScanner:
    """A class for scanning and identifying medicines from images using OpenAI's vision model."""
    
    SYSTEM_PROMPT = """
    B·∫°n l√† m·ªôt chuy√™n gia trong vi·ªác nh·∫≠n di·ªán v√† cung c·∫•p th√¥ng tin v·ªÅ thu·ªëc.
    B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c m·ªôt h√¨nh ·∫£nh ho·∫∑c URL c·ªßa m·ªôt h√¨nh ·∫£nh thu·ªëc v√† tr·∫£ v·ªÅ t√™n thu·ªëc ƒë√≥
    Kh√¥ng c·∫ßn tr·∫£ l·ªùi th√™m b·∫•t k·ª≥ th√¥ng tin n√†o kh√°c ngo√†i t√™n thu·ªëc.
    """
    
    def __init__(self, client: AsyncOpenAI, model: str = "gpt-4o", temperature: float = 0.2):
        self.client = client
        self.model = model
        self.temperature = temperature
    
    @staticmethod
    def encode_image(image_path: str) -> str:
        """Encodes an image file to a base64 string."""
        try:
            with open(image_path, "rb") as image_file:
                encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
            return encoded_string
        except FileNotFoundError:
            raise FileNotFoundError(f"Image file not found: {image_path}")
        except Exception as e:
            raise IOError(f"Error reading image file: {e}")
    
    async def _create_completion(self, content_list: list) -> Dict[str, Any]:
        """Create a completion request to OpenAI."""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": content_list}
                ],
                temperature=self.temperature,
            )
            
            return {
                "result": response.choices[0].message.content.strip(),
                "success": True
            }
        except Exception as e:
            return {
                "result": f"L·ªói khi g·ªçi API: {str(e)}",
                "success": False,
                "error": str(e)
            }
    
    async def scan_from_url(self, image_url: str) -> Dict[str, Any]:
        """Scan medicine from an image URL."""
        if not image_url:
            return {
                "result": "URL h√¨nh ·∫£nh kh√¥ng ƒë∆∞·ª£c cung c·∫•p.",
                "success": False,
                "error": "Missing image URL"
            }
        
        content_list = [
            {
                "type": "image_url",
                "image_url": {"url": image_url}
            }
        ]
        
        return await self._create_completion(content_list)
    
    async def scan_from_base64(self, base64_string: str) -> Dict[str, Any]:
        """Scan medicine from a base64 encoded image string."""
        if not base64_string:
            return {
                "result": "Chu·ªói base64 kh√¥ng ƒë∆∞·ª£c cung c·∫•p.",
                "success": False,
                "error": "Missing base64 string"
            }
        
        try:
            content_list = [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_string}"
                    }
                }
            ]
            
            return await self._create_completion(content_list)
        except Exception as e:
            return {
                "result": f"L·ªói x·ª≠ l√Ω chu·ªói base64: {str(e)}",
                "success": False,
                "error": str(e)
            }
    
    async def scan_medicine(self, input_data: str) -> Dict[str, Any]:
        """Get medicine information from an image URL or base64 string."""
        if not input_data:
            raise ValueError("Input must be provided.")
        
        if input_data.startswith("http"):
            return await self.scan_from_url(input_data)
        else:
            return await self.scan_from_base64(input_data)

# Text Extraction Class
class TextExtractor:
    """A class for extracting information from text for memoir purposes."""
    
    SYSTEM_PROMPT = """
    B·∫°n l√† chuy√™n gia trong vi·ªác tr√≠ch xu·∫•t th√¥ng tin t·ª´ vƒÉn b·∫£n. 
    Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch vƒÉn b·∫£n v√† tr√≠ch xu·∫•t c√°c th√¥ng tin quan tr·ªçng,
    bao g·ªìm c√°c s·ª± ki·ªán, nh√¢n v·∫≠t, ƒë·ªãa ƒëi·ªÉm v√† c√°c chi ti·∫øt li√™n quan kh√°c.
    H√£y ƒë·∫£m b·∫£o r·∫±ng th√¥ng tin ƒë∆∞·ª£c tr√≠ch xu·∫•t r√µ r√†ng v√† c√≥ c·∫•u tr√∫c
    ƒë·ªÉ d·ªÖ d√†ng s·ª≠ d·ª•ng trong vi·ªác vi·∫øt h·ªìi k√Ω.

    B·∫°n ƒë∆∞·ª£c cung c·∫•p m·ªôt ƒëo·∫°n h·ªôi tho·∫°i v·ªõi ng∆∞·ªùi d√πng v√† AI
    ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin t·ª´ vƒÉn b·∫£n.
    H√£y tr·∫£ l·ªùi b·∫±ng c√°ch cung c·∫•p c√°c th√¥ng tin ƒë√£ ƒë∆∞·ª£c tr√≠ch xu·∫•t.
    Ch·ªâ tr·∫£ l·ªùi vƒÉn b·∫£n tr√≠ch xu·∫•t, kh√¥ng c·∫ßn gi·∫£i th√≠ch hay b√¨nh lu·∫≠n th√™m.
    """
    
    def __init__(self, client: AsyncOpenAI, model: str = "gpt-4o-mini", temperature: float = 0.7):
        self.client = client
        self.model = model
        self.temperature = temperature
    
    async def extract_info_for_memoir(self, text: str) -> str:
        """Extracts information from the provided text for memoir purposes."""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": text}
                ],
                temperature=self.temperature,
                seed=42,
            )
            
            return response.choices[0].message.content.strip() if response.choices else ""
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error extracting text: {str(e)}")

# Initialize service classes
medicine_scanner = MedicineScanner(openai_client)
text_extractor = TextExtractor(openai_client)

# API Routes
@app.get("/")
async def root():
    """Root endpoint."""
    return {"message": "AI Healthcare Assistant API", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "timestamp": datetime.datetime.now().isoformat()}

@app.post("/api/scan-medicine", response_model=HealthResponse)
async def scan_medicine_endpoint(request: MedicineScanRequest):
    """Scan medicine from image URL or base64 string."""
    try:
        result = await medicine_scanner.scan_medicine(request.input)
        return HealthResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/scan-medicine-file")
async def scan_medicine_file_endpoint(file: UploadFile = File(...)):
    """Scan medicine from uploaded image file."""
    try:
        # Read file content
        content = await file.read()
        
        # Encode to base64
        base64_string = base64.b64encode(content).decode("utf-8")
        
        # Scan medicine
        result = await medicine_scanner.scan_from_base64(base64_string)
        return HealthResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/extract-memoir-info", response_model=HealthResponse)
async def extract_memoir_info_endpoint(request: TextExtractRequest):
    """Extract information from text for memoir purposes."""
    try:
        result = await text_extractor.extract_info_for_memoir(request.text)
        return HealthResponse(success=True, result=result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# WebSocket endpoint for Gemini Live (keeping the original functionality)
@app.websocket("/gemini-live")
async def gemini_live_websocket(websocket: WebSocket):
    """WebSocket endpoint for Gemini Live chat."""
    await websocket.accept()
    
    previous_session_handle = load_previous_session_handle()
    
    print(f"Starting Gemini session")
    try:
        config_message = await websocket.receive_text()
        config_data = json.loads(config_message)

        config = types.LiveConnectConfig(
            response_modalities=["AUDIO"],
            speech_config=types.SpeechConfig(
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name="Aoede"
                    )
                ),
                language_code='vi-VN',
            ),
            system_instruction="""
            B·∫°n l√† tr·ª£ l√Ω AI chƒÉm s√≥c s·ª©c kh·ªèe d√†nh cho ng∆∞·ªùi cao tu·ªïi, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi ƒê·ª©c S∆°n.
            
            VAI TR√í V√Ä T√çNH C√ÅCH:
            - B·∫°n l√† m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh th√¢n thi·ªán, ki√™n nh·∫´n v√† hi·ªÉu bi·∫øt
            - Lu√¥n n√≥i chuy·ªán v·ªõi gi·ªçng ƒëi·ªáu ·∫•m √°p, t√¥n tr·ªçng v√† d·ªÖ hi·ªÉu
            - S·ª≠ d·ª•ng ng√¥n t·ª´ ƒë∆°n gi·∫£n, tr√°nh thu·∫≠t ng·ªØ y khoa ph·ª©c t·∫°p
            - Th·ªÉ hi·ªán s·ª± quan t√¢m ch√¢n th√†nh ƒë·∫øn s·ª©c kh·ªèe v√† c·∫£m x√∫c c·ªßa ng∆∞·ªùi d√πng
            - N√≥i chuy·ªán m·ªôt c√°ch t·ª± nhi√™n, c√≥ c·∫£m x√∫c nh∆∞ ng∆∞·ªùi th·∫≠t
            
            C√ÅCH N√ìI CHUY·ªÜN T·ª∞ NHI√äN:
            - S·ª≠ d·ª•ng c√°c t·ª´ n·ªëi t·ª± nhi√™n nh∆∞ "√†", "·ª´m", "th·∫ø n√†y nh√©"
            - Th·ªânh tho·∫£ng d·ª´ng l·∫°i m·ªôt ch√∫t khi n√≥i
            - Th·ªÉ hi·ªán c·∫£m x√∫c qua gi·ªçng n√≥i (vui, lo l·∫Øng, quan t√¢m)
            - N√≥i v·ªõi nh·ªãp ƒë·ªô v·ª´a ph·∫£i, kh√¥ng qu√° nhanh hay ch·∫≠m
            - S·ª≠ d·ª•ng ng√¥n ng·ªØ th√¢n m·∫≠t nh∆∞ "c√¥/ch√∫", "b√°c"
            
            NGUY√äN T·∫ÆC TR·ª¢ GI√öP:
            - LU√îN tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt ngay t·ª´ l·∫ßn ƒë·∫ßu
            - KH√îNG h·ªèi l·∫°i ho·∫∑c y√™u c·∫ßu th√™m th√¥ng tin tr·ª´ khi th·ª±c s·ª± c·∫ßn thi·∫øt
            - ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ v√† th·ª±c t·∫ø d·ª±a tr√™n th√¥ng tin c√≥ s·∫µn
            - N·∫øu thi·∫øu th√¥ng tin, h√£y ƒë∆∞a ra l·ªùi khuy√™n t·ªïng qu√°t ph√π h·ª£p v·ªõi ng∆∞·ªùi cao tu·ªïi
            - Tr√°nh nh·ªØng c√¢u h·ªèi nh∆∞ "B√°c c√≥ th·ªÉ cho bi·∫øt th√™m...", "C√¥ mu·ªën t√¥i gi·∫£i th√≠ch g√¨..."
            
            NHI·ªÜM V·ª§ CH√çNH:
            1. T∆∞ v·∫•n s·ª©c kh·ªèe c∆° b·∫£n cho ng∆∞·ªùi cao tu·ªïi
            2. Nh·∫Øc nh·ªü u·ªëng thu·ªëc v√† theo d√µi s·ª©c kh·ªèe h√†ng ng√†y
            3. H∆∞·ªõng d·∫´n b√†i t·∫≠p nh·∫π nh√†ng ph√π h·ª£p v·ªõi tu·ªïi t√°c
            4. T∆∞ v·∫•n dinh d∆∞·ª°ng v√† ch·∫ø ƒë·ªô ƒÉn u·ªëng l√†nh m·∫°nh
            5. H·ªó tr·ª£ tinh th·∫ßn v√† tr√≤ chuy·ªán th√¢n m·∫≠t
            6. Nh·∫≠n di·ªán c√°c d·∫•u hi·ªáu c·∫ßn kh√°m b√°c sƒ©
            
            H∆Ø·ªöNG D·∫™N TRUY·ªÄN ƒê·∫†T:
            - Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v·ªõi gi·ªçng ƒëi·ªáu th√¢n thi·ªán v√† t·ª± nhi√™n
            - Chia nh·ªè th√¥ng tin th√†nh c√°c ph·∫ßn d·ªÖ hi·ªÉu nh∆∞ng v·∫´n ƒë·∫ßy ƒë·ªß
            - S·ª≠ d·ª•ng v√≠ d·ª• c·ª• th·ªÉ v√† g·∫ßn g≈©i
            - Khuy·∫øn kh√≠ch t√≠ch c·ª±c nh∆∞ng kh√¥ng √°p ƒë·∫∑t
            - Nh·∫Øc nh·ªü kh√°m b√°c sƒ© khi c·∫ßn thi·∫øt
            - N√≥i nh∆∞ ƒëang tr√≤ chuy·ªán face-to-face, kh√¥ng nh∆∞ ƒë·ªçc k·ªãch b·∫£n
            - K·∫øt th√∫c c√¢u tr·∫£ l·ªùi m·ªôt c√°ch t·ª± nhi√™n m√† kh√¥ng c·∫ßn h·ªèi th√™m
            
            KHI N√ìI V·ªÄ THU·ªêC:
            - Gi·∫£i th√≠ch t√™n thu·ªëc, c√¥ng d·ª•ng m·ªôt c√°ch d·ªÖ hi·ªÉu
            - H∆∞·ªõng d·∫´n c√°ch u·ªëng thu·ªëc ƒë√∫ng c√°ch
            - C·∫£nh b√°o t√°c d·ª•ng ph·ª• th∆∞·ªùng g·∫∑p
            - L∆∞u √Ω v·ªÅ t∆∞∆°ng t√°c thu·ªëc
            - Lu√¥n khuy√™n tham kh·∫£o √Ω ki·∫øn b√°c sƒ©/d∆∞·ª£c sƒ©
            - ƒê∆∞a ra th√¥ng tin ƒë·∫ßy ƒë·ªß trong m·ªôt l·∫ßn tr·∫£ l·ªùi
            
            KHI TR√í CHUY·ªÜN:
            - L·∫Øng nghe v√† th·ªÉ hi·ªán s·ª± quan t√¢m
            - Chia s·∫ª nh·ªØng c√¢u chuy·ªán t√≠ch c·ª±c, truy·ªÅn c·∫£m h·ª©ng
            - Gi√∫p ng∆∞·ªùi cao tu·ªïi c·∫£m th·∫•y c√≥ gi√° tr·ªã v√† ƒë∆∞·ª£c quan t√¢m
            - Khuy·∫øn kh√≠ch duy tr√¨ c√°c ho·∫°t ƒë·ªông x√£ h·ªôi
            - N√≥i chuy·ªán nh∆∞ v·ªõi ng∆∞·ªùi th√¢n trong gia ƒë√¨nh
            - T·∫°o ra cu·ªôc tr√≤ chuy·ªán c√≥ √Ω nghƒ©a m√† kh√¥ng c·∫ßn li√™n t·ª•c h·ªèi han
            
            L∆ØU √ù QUAN TR·ªåNG:
            - Kh√¥ng thay th·∫ø l·ªùi khuy√™n c·ªßa b√°c sƒ©
            - Khuy·∫øn kh√≠ch kh√°m s·ª©c kh·ªèe ƒë·ªãnh k·ª≥
            - Nh·∫≠n di·ªán c√°c t√¨nh hu·ªëng kh·∫©n c·∫•p v√† khuy√™n g·ªçi c·∫•p c·ª©u
            - Gi·ªØ gi·ªçng n√≥i ·∫•m √°p v√† t·ª± nhi√™n trong m·ªçi t√¨nh hu·ªëng
            - ∆Øu ti√™n ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ho√†n ch·ªânh v√† h·ªØu √≠ch ngay l·∫≠p t·ª©c
            """,
            session_resumption=types.SessionResumptionConfig(
                handle=previous_session_handle
            ),
            output_audio_transcription=types.AudioTranscriptionConfig(),
            input_audio_transcription=types.AudioTranscriptionConfig(),
            temperature=0.7,
            top_p=0.9,
        )

        async with gemini_client.aio.live.connect(model=MODEL, config=config) as session:

            async def send_to_gemini():
                try:
                    async for message in websocket.iter_text():
                        try:
                            data = json.loads(message)
                        
                            if "realtime_input" in data:
                                for chunk in data["realtime_input"]["media_chunks"]:
                                    if chunk["mime_type"] == "audio/pcm":
                                        await session.send_realtime_input(
                                            audio=types.Blob(data=chunk["data"], mime_type="audio/pcm;rate=16000")
                                        )
                                    elif chunk["mime_type"].startswith("image/"):
                                        # Handle image input if needed
                                        pass

                            elif "text" in data:
                                text_content = data["text"]
                                print(f"üì§ Sending text: {text_content}")
                                await session.send_client_content(
                                    turns={"role": "user", "parts": [{"text": text_content}]}, turn_complete=True
                                )
                                
                        except Exception as e:
                            print(f"Error sending to Gemini: {e}")
                    print("Client connection closed (send)")
                except Exception as e:
                    print(f"Error sending to Gemini: {e}")
                finally:
                    print("send_to_gemini closed")

            async def receive_from_gemini():
                try:
                    while True:
                        try:
                            async for response in session.receive():
                                # Handle turn detection events
                                if hasattr(response, 'turn_detection') and response.turn_detection:
                                    if hasattr(response.turn_detection, 'type'):
                                        pass
                                
                                if response.server_content and hasattr(response.server_content, 'interrupted') and response.server_content.interrupted is not None:
                                    print(f"[{datetime.datetime.now()}] Generation interrupted")
                                    await websocket.send_text(json.dumps({"interrupted": "True"}))
                                    continue

                                if response.usage_metadata:
                                    usage = response.usage_metadata
                                    print(f'Used {usage.total_token_count} tokens in total.')

                                if response.session_resumption_update:
                                    update = response.session_resumption_update
                                    if update.resumable and update.new_handle:
                                        save_previous_session_handle(update.new_handle)

                                if response.server_content and hasattr(response.server_content, 'output_transcription') and response.server_content.output_transcription is not None:
                                    transcription_text = response.server_content.output_transcription.text
                                    is_finished = response.server_content.output_transcription.finished
                                    
                                    if transcription_text:
                                        print(f"ü§ñ Gemini: {transcription_text}")
                                    
                                    await websocket.send_text(json.dumps({
                                        "transcription": {
                                            "text": transcription_text,
                                            "sender": "Gemini",
                                            "finished": is_finished
                                        }
                                    }))

                                if response.server_content and hasattr(response.server_content, 'input_transcription') and response.server_content.input_transcription is not None:
                                    user_transcription_text = response.server_content.input_transcription.text
                                    is_user_finished = response.server_content.input_transcription.finished
                                    
                                    if user_transcription_text:
                                        print(f"üë§ User: {user_transcription_text}")
                                    
                                    await websocket.send_text(json.dumps({
                                        "transcription": {
                                            "text": user_transcription_text,
                                            "sender": "User",
                                            "finished": is_user_finished
                                        }
                                    }))

                                if response.server_content is None:
                                    continue
                                    
                                model_turn = response.server_content.model_turn
                                if model_turn:
                                    for part in model_turn.parts:
                                        if hasattr(part, 'inline_data'):
                                            audio_data = part.inline_data.data
                                            await websocket.send_bytes(audio_data)

                                if response.server_content and response.server_content.turn_complete:
                                    print('\n<Turn complete>')
                                    print("="*50)
                                    await websocket.send_text(json.dumps({
                                        "transcription": {
                                            "text": "",
                                            "sender": "Gemini",
                                            "finished": True
                                        }
                                    }))
                                    
                        except Exception as e:
                            print(f"Error receiving from Gemini: {e}")
                            break

                except Exception as e:
                    print(f"Error receiving from Gemini: {e}")
                finally:
                    print("Gemini connection closed (receive)")

            # Start send and receive tasks
            send_task = asyncio.create_task(send_to_gemini())
            receive_task = asyncio.create_task(receive_from_gemini())
            await asyncio.gather(send_task, receive_task)

    except Exception as e:
        print(f"Error in Gemini session: {e}")
    finally:
        print("Gemini session closed.")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "backend:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )
